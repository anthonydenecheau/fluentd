<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# add a parser filter
# parser filter will parse our JSON formatted log and store it in Elasticsearch for Grafana to read.
<filter scc.judgeservice>
  @type parser
  format json
  key_name log
  time_key time
  time_format %Y-%m-%dT%H:%M:%S.%N
  reserve_data true
</filter>

# Using filter to add container IDs to each event
<filter docker.var.lib.docker.containers.*.*.log>
  @type record_transformer
  <record>
    container_id ${tag_parts[5]}
  </record>
</filter>

# set where we're going to store our logs
<match **>
  @type elasticsearch
  logstash_prefix mylogs
  logstash_format true
  host elasticsearch
  port 9200
  <buffer tag>
  	flush_mode interval
  	flush_interval 5s
  </buffer>
  index_name fluentd
  type_name fluentd  
</match>